# Awesome-Interpretability-in-Large-Language-Models

# Awesome Interpretability Libraries
- ![GitHub Repo stars](https://img.shields.io/github/stars/TransformerLensOrg/TransformerLens) [**TransformerLens**](https://github.com/TransformerLensOrg/TransformerLens): A Library for Mechanistic Interpretability of Generative Language Models. ([Doc](https://transformerlensorg.github.io/TransformerLens/), [Tutorial](https://arena3-chapter1-transformer-interp.streamlit.app/[1.2]_Intro_to_Mech_Interp), [Demo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb))
- ![GitHub Repo stars](https://img.shields.io/github/stars/ndif-team/nnsight) [**nnsight**](https://github.com/ndif-team/nnsight): enables interpreting and manipulating the internals of deep learned models. ([Doc](https://nnsight.net/documentation/), [Tutorial](https://nnsight.net/tutorials/))
- ![GitHub Repo stars](https://img.shields.io/github/stars/jbloomAus/SAELens) [**SAE Lens**](https://github.com/jbloomAus/SAELens): train and analyse SAE. ([Doc](https://jbloomaus.github.io/SAELens/), [Tutorial](https://github.com/jbloomAus/SAELens/tree/main/tutorials))

# Awesome Interpretability Papers

## Survey Papers

|  Title  |   Venue  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|
|[**Mechanistic Interpretability for AI Safety -- A Review**](https://arxiv.org/pdf/2404.14082)| arXiv | 2024-04-22 | - |
|[**From Understanding to Utilization: A Survey on Explainability for Large Language Models**](https://arxiv.org/pdf/2401.12874v2)| arXiv | 2024-02-22 | - |
|[**Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks**](https://arxiv.org/pdf/2207.13243)| arXiv | 2023-08-18 | - |

## Position Papers

|  Title  |   Venue  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|
|[**Position Paper: An Inner Interpretability Framework for AI Inspired by Lessons from Cognitive Neuroscience**](https://arxiv.org/pdf/2406.01352v1)| ICML | 2024-06-03 | - |
|[**Interpretability Needs a New Paradigm**](https://arxiv.org/pdf/2405.05386v1)| arXiv | 2024-05-08 | - |
|[**Position Paper: Toward New Frameworks for Studying Model Representations**](https://arxiv.org/pdf/2402.03855v1)| arXiv | 2024-02-06 | - |
|[**Rethinking Interpretability in the Era of Large Language Models**](https://arxiv.org/pdf/2402.01761v1)| arXiv | 2024-01-30 | - |

## Interpretable Analysis of LLMs
|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![GitHub Repo stars](https://img.shields.io/github/stars/JasonGross/guarantees-based-mechanistic-interpretability) <br> [**Compact Proofs of Model Performance via Mechanistic Interpretability**](https://arxiv.org/pdf/2406.11779) <br>| arXiv | 2024-06-24 | [Github](https://github.com/JasonGross/guarantees-based-mechanistic-interpretability/) | - |
| [**Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models**](https://arxiv.org/pdf/2406.16033) <br>| arXiv | 2024-06-23 | - | - |
| [**Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations**](https://arxiv.org/pdf/2403.18167v2) <br>| arXiv | 2024-06-17 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/jacobdunefsky/transcoder_circuits) <br> [**Transcoders Find Interpretable LLM Feature Circuits**](https://arxiv.org/pdf/2406.11944) <br>| arXiv | 2024-06-17 | [Github](https://github.com/jacobdunefsky/transcoder_circuits) | - |
| [**Interpretability Illusions in the Generalization of Simplified Models**](https://arxiv.org/pdf/2406.02128v1) <br>| arXiv | 2024-06-04 | - | - |
| [**Iteration Head: A Mechanistic Study of Chain-of-Thought**](https://arxiv.org/pdf/2312.03656) <br>| arXiv | 2024-06-05 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/samuelperezdi/nuclr-icml) <br> [**From Neurons to Neutrons: A Case Study in Interpretability**](https://arxiv.org/pdf/2405.17425) <br>| ICML | 2024-05-27 | [Github](https://github.com/samuelperezdi/nuclr-icml)| - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/starship006/backup_research) <br> [**Explorations of Self-Repair in Language Models**](https://arxiv.org/pdf/2402.15390v2) <br>| ICML | 2024-05-26 | [Github](https://github.com/starship006/backup_research)| - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/ruizheliUOA/Anchored_Bias_GPT2) <br> [**Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions**](https://arxiv.org/pdf/2405.03205v2) <br>| arXiv | 2024-05-23 | [Github](https://github.com/ruizheliUOA/Anchored_Bias_GPT2)| - |
| [**Using Degeneracy in the Loss Landscape for Mechanistic Interpretability**](https://arxiv.org/pdf/2405.10927) <br>| arXiv | 2024-05-20 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/jgcarrasco/acronyms_paper) <br> [**How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability**](https://arxiv.org/pdf/2405.04156) <br>| AISTATS | 2024-05-07 | [Github](https://github.com/jgcarrasco/acronyms_paper)| - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/joykirat18/How-To-Think-Step-by-Step) <br> [**How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning**](https://arxiv.org/pdf/2402.18312) <br>| arXiv | 2024-05-06 | [Github](https://github.com/joykirat18/How-To-Think-Step-by-Step)| - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/jmerullo/circuit_reuse) <br> [**Circuit Component Reuse Across Tasks in Transformer Language Models**](https://arxiv.org/pdf/2310.08744) <br>| ICLR | 2024-05-06 | [Github](https://github.com/jmerullo/circuit_reuse)| - |
| [**How to use and interpret activation patching**](https://arxiv.org/pdf/2404.15255v1) <br>| arXiv | 2024-04-23 | - | - |
| [**Understanding Addition in Transformers**](https://arxiv.org/pdf/2310.13121v9) <br>| arXiv | 2024-04-23 | - | - |
| [**Towards Uncovering How Large Language Model Works: An Explainability Perspective**](https://arxiv.org/pdf/2402.10688) <br>| arXiv | 2024-04-15 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/aadityasingh/icl-dynamics) <br> [**What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation**](https://arxiv.org/pdf/2404.07129) <br>| ICML | 2024-04-10 | [Github](https://github.com/aadityasingh/icl-dynamics)| - |
| [**Does Transformer Interpretability Transfer to RNNs?**](https://arxiv.org/pdf/2404.05971v1) <br>| arXiv | 2024-04-09 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/saprmarks/feature-circuits) <br> [**Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models**](https://arxiv.org/pdf/2403.19647v2) <br>| arXiv | 2024-03-31 | [Github](https://github.com/saprmarks/feature-circuits)| [Demo](https://feature-circuits.xyz/) |
| [**A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task**](https://arxiv.org/pdf/2402.11917) <br>| arXiv | 2024-02-28 | - | - |
| [**A Language Model's Guide Through Latent Space**](https://arxiv.org/pdf/2402.14433) <br>| arXiv | 2024-02-22 | - | - |
| [**Interpreting Shared Circuits for Ordered Sequence Prediction in a Large Language Model**](https://arxiv.org/pdf/2311.04131v3) <br>| arXiv | 2024-02-22 | - | - |
| [**Identifying Semantic Induction Heads to Understand In-Context Learning**](https://arxiv.org/pdf/2402.13055) <br>| arXiv | 2024-02-20 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/ejmichaud/neural-verification) <br> [**Opening the AI black box: program synthesis via mechanistic interpretability**](https://arxiv.org/pdf/2402.05110) <br>| arXiv | 2024-02-07 | [Github](https://github.com/ejmichaud/neural-verification)| - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/wesg52/universal-neurons) <br> [**Universal Neurons in GPT2 Language Models**](https://arxiv.org/pdf/2401.12181) <br>| arXiv | 2024-01-22 | [Github](https://github.com/wesg52/universal-neurons)| - |
| [**Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks**](https://openreview.net/pdf?id=A0HKeKl4Nl) <br>| ICLR | 2024-01-16 | - | - |
| [**Successor Heads: Recurring, Interpretable Attention Heads In The Wild**](https://openreview.net/pdf?id=kvcbV8KQsi) <br>| ICLR | 2024-01-16 | - | - |
| [**Towards Best Practices of Activation Patching in Language Models: Metrics and Methods**](https://openreview.net/pdf?id=Hf17y6u9BC) <br>| ICLR | 2024-01-16 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/ajyl/dpo_toxic) <br> [**A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity**](https://arxiv.org/pdf/2401.01967) <br>| arXiv | 2024-01-03 |  [Github](https://github.com/ajyl/dpo_toxic) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/ed1d1a8d/prompt-injection-interp) <br> [**Forbidden Facts: An Investigation of Competing Objectives in Llama-2**](https://arxiv.org/pdf/2312.08793) <br>| ATTRIB@NeurIPS | 2023-12-31 |  [Github](https://github.com/ed1d1a8d/prompt-injection-interp) | [Blog](https://www.lesswrong.com/posts/Ei8q37PB3cAky6kaK/) |
| ![GitHub Repo stars](https://img.shields.io/github/stars/amakelov/activation-patching-illusion) <br> [**Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching**](https://arxiv.org/pdf/2311.17030) <br>| ATTRIB@NeurIPS | 2023-12-06 |  [Github](https://github.com/amakelov/activation-patching-illusion) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/understanding-search/structured-representations-maze-transformers) <br> [**Structured World Representations in Maze-Solving Transformers**](https://arxiv.org/pdf/2312.02566) <br>| UniReps@NeurIPS | 2023-12-05 |  [Github](https://github.com/understanding-search/structured-representations-maze-transformers) | - |
| [**Generating Interpretable Networks using Hypernetworks**](https://arxiv.org/pdf/2312.03051) <br>| arXiv | 2023-12-05 |  - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/fjzzq2002/pizza) <br> [**The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks**](https://arxiv.org/pdf/2306.17844) <br>| NeurIPS | 2023-11-21 | [Github](https://github.com/fjzzq2002/pizza) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/google-deepmind/tracr) <br> [**Tracr: Compiled Transformers as a Laboratory for Interpretability**](https://arxiv.org/pdf/2301.05062) <br>| NeurIPS | 2023-11-03 | [Github](https://github.com/google-deepmind/tracr) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/hannamw/gpt2-greater-than) <br> [**How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model**](https://arxiv.org/pdf/2305.00586) <br>| NeurIPS | 2023-11-02 | [Github](https://github.com/hannamw/gpt2-greater-than) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/princeton-nlp/TransformerPrograms) <br> [**Learning Transformer Programs**](https://arxiv.org/pdf/2306.01128) <br>| NeurIPS | 2023-10-31 | [Github](https://github.com/princeton-nlp/TransformerPrograms) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/ArthurConmy/Automatic-Circuit-Discovery) <br> [**Towards Automated Circuit Discovery for Mechanistic Interpretability**](https://arxiv.org/pdf/2304.14997) <br>| NeurIPS | 2023-10-28 | [Github](https://github.com/ArthurConmy/Automatic-Circuit-Discovery) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/yifan-h/MechanisticProbe) <br> [**Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models**](https://arxiv.org/pdf/2310.14491) <br>| EMNLP | 2023-10-23 | [Github](https://github.com/yifan-h/MechanisticProbe) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/mechanistic-interpretability-grokking/progress-measures-paper) <br> [**Progress measures for grokking via mechanistic interpretability**](https://arxiv.org/pdf/2301.05217) <br>| ICLR | 2023-10-19 | [Github](https://github.com/mechanistic-interpretability-grokking/progress-measures-paper) | [Blog](https://www.neelnanda.io/grokking-paper) |
| ![GitHub Repo stars](https://img.shields.io/github/stars/callummcdougall/SERI-MATS-2023-Streamlit-pages) <br> [**Copy Suppression: Comprehensively Understanding an Attention Head**](https://arxiv.org/pdf/2310.04625) <br>| arXiv | 2023-10-06 | [Github](https://github.com/callummcdougall/SERI-MATS-2023-Streamlit-pages) | [Blog & Demo](https://copy-suppression.streamlit.app/) |
| ![GitHub Repo stars](https://img.shields.io/github/stars/bilal-chughtai/rep-theory-mech-interp) <br> [**A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations**](https://arxiv.org/pdf/2302.03025) <br>| ICML | 2023-05-24 | [Github](https://github.com/bilal-chughtai/rep-theory-mech-interp) | - |
| [**Localizing Model Behavior with Path Patching**](https://arxiv.org/pdf/2304.05969) <br>| arXiv | 2023-05-16 | - | - |
| [**N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models**](https://arxiv.org/pdf/2304.12918) <br>| ICLR Workshop | 2023-04-22 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/redwoodresearch/Easy-Transformer) <br> [**Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small**](https://arxiv.org/pdf/2211.00593) <br>| ICLR | 2023-01-20 | [Github](https://github.com/redwoodresearch/Easy-Transformer) | - |
| [**Interpreting Neural Networks through the Polytope Lens**](https://arxiv.org/pdf/2211.12312) <br>| arXiv | 2022-11-22 | - | - |
| [**Scaling Laws and Interpretability of Learning from Repeated Data**](https://arxiv.org/pdf/2205.10487) <br>| arXiv | 2022-05-21 | - | - |

## SAE and Dictionary Learning

|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**Interpreting Attention Layer Outputs with Sparse Autoencoders**](https://arxiv.org/pdf/2406.17759v1) <br>| arXiv | 2024-06-25 | - | [Demo](https://robertzk.github.io/circuit-explorer) |
| [**Improving Language Models Trained with Translated Data via Continual Pre-Training and Dictionary Learning Analysis**](https://arxiv.org/pdf/2405.14277) <br>| arXiv | 2024-05-23 | - | - |
| [**Automatically Identifying Local and Global Circuits with Linear Computation Graphs**](https://arxiv.org/pdf/2405.13868v1) <br>| arXiv | 2024-05-22 | - | - |
| [**Improving Dictionary Learning with Gated Sparse Autoencoders**](https://arxiv.org/pdf/2404.16014v2) <br>| arXiv | 2024-04-30 | - | - |
| [**Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT**](https://arxiv.org/pdf/2402.12201) <br>| arXiv | 2024-02-19 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/HoagyC/sparse_coding) <br> [**Sparse Autoencoders Find Highly Interpretable Features in Language Models**](https://openreview.net/pdf?id=F76bwRSLeK) <br>| ICLR | 2024-01-16 | [Github](https://github.com/HoagyC/sparse_coding) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/anthropics/toy-models-of-superposition) <br> [**Toy Models of Superposition**](https://transformer-circuits.pub/2022/toy_model/index.html) <br>| Anthropic | 2022-09-14 | [Github](https://github.com/anthropics/toy-models-of-superposition) | - |


## Interpretability in Vision LLMs

|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![GitHub Repo stars](https://img.shields.io/github/stars/wrudman/NOTICE) <br> [**What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Noise-free Text-Image Corruption and Evaluation**](https://arxiv.org/pdf/2406.16320) <br>| arXiv | 2024-06-24 | [Github](https://github.com/wrudman/NOTICE) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/maxdreyer/PURE) <br> [**PURE: Turning Polysemantic Neurons Into Pure Features by Identifying Relevant Circuits**](https://arxiv.org/pdf/2404.06453v1) <br>| XAI4CV@CVPR | 2024-04-09 | [Github](https://github.com/maxdreyer/PURE) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/AI4LIFE-GROUP/SpLiCE) <br> [**Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)**](https://arxiv.org/pdf/2402.10376v1) <br>| arXiv | 2024-02-16 | [Github](https://github.com/AI4LIFE-GROUP/SpLiCE) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability) <br> [**Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP**](https://arxiv.org/pdf/2308.14179) <br>| CLVL@ICCV | 2023-08-27 | [Github](https://github.com/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability) | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/brendel-group/imi) <br> [**Scale Alone Does not Improve Mechanistic Interpretability in Vision Models**](https://arxiv.org/pdf/2307.05471) <br>| NeurIPS | 2023-07-11 | [Github](https://github.com/brendel-group/imi) | [Blog](https://brendel-group.github.io/imi/) |

## Benchmarking Interpretability

|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**Benchmarking Mental State Representations in Language Models**](https://arxiv.org/pdf/2406.17513) <br>| MI@ICML | 2024-06-25 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/aryamanarora/causalgym) <br> [**CausalGym: Benchmarking causal interpretability methods on linguistic tasks**](https://arxiv.org/pdf/2402.12560) <br>| arXiv | 2024-02-19 | [Github](https://github.com/aryamanarora/causalgym) | - |

## Enhancing Interpretability

|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**Evaluating Brain-Inspired Modular Training in Automated Circuit Discovery for Mechanistic Interpretability**](https://arxiv.org/pdf/2401.03646) <br>| arXiv | 2024-01-08 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/KindXiaoming/BIMT) <br> [**Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability**](https://arxiv.org/pdf/2305.08746) <br>| arXiv | 2023-06-06 | [Github](https://github.com/KindXiaoming/BIMT) | - |

## Others

|  Title  |   Venue  |   Date   |   Code   |   Blog   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [**An introduction to graphical tensor notation for mechanistic interpretability**](https://arxiv.org/pdf/2402.01790) <br>| arXiv | 2024-02-02 | - | - |
| ![GitHub Repo stars](https://img.shields.io/github/stars/arjunkaruvally/emt_variable_binding) <br> [**Episodic Memory Theory for the Mechanistic Interpretation of Recurrent Neural Networks**](https://arxiv.org/pdf/2310.02430) <br>| arXiv | 2023-10-03 | [Github](https://github.com/arjunkaruvally/emt_variable_binding) | - |





# Awesome Interpretability Blogs

# Awesome Interpretability Tutorials

# Awesome Interpretability Forums

# Awesome Interpretability Datasets

# Awesome Interpretability Tools

# Awesome Interpretability Programs

# Other Awesome Interpretability Resources